<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="zh_TW">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>配置 &#8212; django-channels-tw-docs 0.0.1 說明文件</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/translations.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜尋" href="search.html" />
    <link rel="next" title="一般消費者" href="generics.html" />
    <link rel="prev" title="Getting Started with Channels" href="getting-started.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="deploying">
<h1>配置<a class="headerlink" href="#deploying" title="本標題的永久連結">¶</a></h1>
<p>Deploying applications using channels requires a few more steps than a normal
Django WSGI application, but you have a couple of options as to how to deploy
it and how much of your traffic you wish to route through the channel layers.</p>
<p>Firstly, remember that it&#8217;s an entirely optional part of Django.
If you leave a project with the default settings (no <code class="docutils literal"><span class="pre">CHANNEL_LAYERS</span></code>),
it&#8217;ll just run and work like a normal WSGI app.</p>
<p>當你想在作業上啟用 channels，你需要做這3件事情:</p>
<ul class="simple">
<li><p class="first">設一個 channel 後端</p>
</li>
<li><p class="first">執行使用者伺服器</p>
</li>
<li>Run interface servers</li>
</ul>
<p>You can set things up in one of two ways; either route all traffic through
a <a class="reference internal" href="#asgi-alone"><span class="std std-ref">HTTP/WebSocket interface server</span></a>, removing the need
to run a WSGI server at all; or, just route WebSockets and long-poll
HTTP connections to the interface server, and <a class="reference internal" href="#wsgi-with-asgi"><span class="std std-ref">leave other pages served
by a standard WSGI server</span></a>.</p>
<p>Routing all traffic through the interface server lets you have WebSockets and
long-polling coexist in the same URL tree with no configuration; if you split
the traffic up, you&#8217;ll need to configure a webserver or layer 7 loadbalancer
in front of the two servers to route requests to the correct place based on
path or domain. Both methods are covered below.</p>
<div class="section" id="setting-up-a-channel-backend">
<h2>Setting up a channel backend<a class="headerlink" href="#setting-up-a-channel-backend" title="本標題的永久連結">¶</a></h2>
<p>The first step is to set up a channel backend. If you followed the
<a class="reference internal" href="getting-started.html"><span class="doc">Getting Started with Channels</span></a> guide, you will have ended up using the in-memory
backend, which is useful for <code class="docutils literal"><span class="pre">runserver</span></code>, but as it only works inside the
same process, useless for actually running separate worker and interface
servers.</p>
<p>Instead, take a look at the list of <a class="reference internal" href="backends.html"><span class="doc">通道層類型</span></a>, and choose one that
fits your requirements (additionally, you could use a third-party pluggable
backend or write your own - that page also explains the interface and rules
a backend has to follow).</p>
<p>Typically a channel backend will connect to one or more central servers that
serve as the communication layer - for example, the Redis backend connects
to a Redis server. All this goes into the <code class="docutils literal"><span class="pre">CHANNEL_LAYERS</span></code> setting;
here&#8217;s an example for a remote Redis server:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CHANNEL_LAYERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;BACKEND&quot;</span><span class="p">:</span> <span class="s2">&quot;asgi_redis.RedisChannelLayer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;CONFIG&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;hosts&quot;</span><span class="p">:</span> <span class="p">[(</span><span class="s2">&quot;redis-server-name&quot;</span><span class="p">,</span> <span class="mi">6379</span><span class="p">)],</span>
        <span class="p">},</span>
        <span class="s2">&quot;ROUTING&quot;</span><span class="p">:</span> <span class="s2">&quot;my_project.routing.channel_routing&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To use the Redis backend you have to install it:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">asgi_redis</span>
</pre></div>
</div>
<p>Some backends, though, don&#8217;t require an extra server, like the IPC backend,
which works between processes on the same machine but not over the network
(it&#8217;s available in the <code class="docutils literal"><span class="pre">asgi_ipc</span></code> package):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CHANNEL_LAYERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;BACKEND&quot;</span><span class="p">:</span> <span class="s2">&quot;asgi_ipc.IPCChannelLayer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ROUTING&quot;</span><span class="p">:</span> <span class="s2">&quot;my_project.routing.channel_routing&quot;</span><span class="p">,</span>
        <span class="s2">&quot;CONFIG&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;prefix&quot;</span><span class="p">:</span> <span class="s2">&quot;mysite&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Make sure the same settings file is used across all your workers and interface
servers; without it, they won&#8217;t be able to talk to each other and things
will just fail to work.</p>
</div>
<div class="section" id="run-worker-servers">
<h2>執行使用者伺服器<a class="headerlink" href="#run-worker-servers" title="本標題的永久連結">¶</a></h2>
<p>Because the work of running consumers is decoupled from the work of talking
to HTTP, WebSocket and other client connections, you need to run a cluster
of &#8220;worker servers&#8221; to do all the processing.</p>
<p>Each server is single-threaded, so it&#8217;s recommended you run around one or two per
core on each machine; it&#8217;s safe to run as many concurrent workers on the same
machine as you like, as they don&#8217;t open any ports (all they do is talk to
the channel backend).</p>
<p>To run a worker server, just run:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">runworker</span>
</pre></div>
</div>
<p>Make sure you run this inside an init system or a program like supervisord that
can take care of restarting the process when it exits; the worker server has
no retry-on-exit logic, though it will absorb tracebacks from inside consumers
and forward them to stderr.</p>
<p>Make sure you keep an eye on how busy your workers are; if they get overloaded,
requests will take longer and longer to return as the messages queue up
(until the expiry or capacity limit is reached, at which point HTTP connections will
start dropping).</p>
<p>In a more complex project, you won&#8217;t want all your channels being served by the
same workers, especially if you have long-running tasks (if you serve them from
the same workers as HTTP requests, there&#8217;s a chance long-running tasks could
block up all the workers and delay responding to HTTP requests).</p>
<p>To manage this, it&#8217;s possible to tell workers to either limit themselves to
just certain channel names or ignore specific channels using the
<code class="docutils literal"><span class="pre">--only-channels</span></code> and <code class="docutils literal"><span class="pre">--exclude-channels</span></code> options. Here&#8217;s an example
of configuring a worker to only serve HTTP and WebSocket requests:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">runworker</span> <span class="o">--</span><span class="n">only</span><span class="o">-</span><span class="n">channels</span><span class="o">=</span><span class="n">http</span><span class="o">.*</span> <span class="o">--</span><span class="n">only</span><span class="o">-</span><span class="n">channels</span><span class="o">=</span><span class="n">websocket</span><span class="o">.*</span>
</pre></div>
</div>
<p>Or telling a worker to ignore all messages on the &#8220;thumbnail&#8221; channel:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">manage</span><span class="o">.</span><span class="n">py</span> <span class="n">runworker</span> <span class="o">--</span><span class="n">exclude</span><span class="o">-</span><span class="n">channels</span><span class="o">=</span><span class="n">thumbnail</span>
</pre></div>
</div>
</div>
<div class="section" id="run-interface-servers">
<h2>Run interface servers<a class="headerlink" href="#run-interface-servers" title="本標題的永久連結">¶</a></h2>
<p>The final piece of the puzzle is the &#8220;interface servers&#8221;, the processes that
do the work of taking incoming requests and loading them into the channels
system.</p>
<p>If you want to support WebSockets, long-poll HTTP requests and other Channels
features, you&#8217;ll need to run a native ASGI interface server, as the WSGI
specification has no support for running these kinds of requests concurrently.
We ship with an interface server that we recommend you use called
<a class="reference external" href="http://github.com/django/daphne/">Daphne</a>; it supports WebSockets,
long-poll HTTP requests, HTTP/2 <em>(soon)</em> and performs quite well.</p>
<p>You can just keep running your Django code as a WSGI app if you like, behind
something like uwsgi or gunicorn; this won&#8217;t let you support WebSockets, though,
so you&#8217;ll need to run a separate interface server to terminate those connections
and configure routing in front of your interface and WSGI servers to route
requests appropriately.</p>
<p>If you use Daphne for all traffic, it auto-negotiates between HTTP and WebSocket,
so there&#8217;s no need to have your WebSockets on a separate domain or path (and
they&#8217;ll be able to share cookies with your normal view code, which isn&#8217;t
possible if you separate by domain rather than path).</p>
<p>To run Daphne, it just needs to be supplied with a channel backend, in much
the same way a WSGI server needs to be given an application.
First, make sure your project has an <code class="docutils literal"><span class="pre">asgi.py</span></code> file that looks like this
(it should live next to <code class="docutils literal"><span class="pre">wsgi.py</span></code>):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">channels.asgi</span> <span class="k">import</span> <span class="n">get_channel_layer</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;DJANGO_SETTINGS_MODULE&quot;</span><span class="p">,</span> <span class="s2">&quot;my_project.settings&quot;</span><span class="p">)</span>

<span class="n">channel_layer</span> <span class="o">=</span> <span class="n">get_channel_layer</span><span class="p">()</span>
</pre></div>
</div>
<p>Then, you can run Daphne and supply the channel layer as the argument:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">daphne</span> <span class="n">my_project</span><span class="o">.</span><span class="n">asgi</span><span class="p">:</span><span class="n">channel_layer</span>
</pre></div>
</div>
<p>Like <code class="docutils literal"><span class="pre">runworker</span></code>, you should place this inside an init system or something
like supervisord to ensure it is re-run if it exits unexpectedly.</p>
<p>If you only run Daphne and no workers, all of your page requests will seem to
hang forever; that&#8217;s because Daphne doesn&#8217;t have any worker servers to handle
the request and it&#8217;s waiting for one to appear (while <code class="docutils literal"><span class="pre">runserver</span></code> also uses
Daphne, it launches worker threads along with it in the same process). In this
scenario, it will eventually time out and give you a 503 error after 2 minutes;
you can configure how long it waits with the <code class="docutils literal"><span class="pre">--http-timeout</span></code> command line
argument.</p>
</div>
<div class="section" id="deploying-new-versions-of-code">
<h2>Deploying new versions of code<a class="headerlink" href="#deploying-new-versions-of-code" title="本標題的永久連結">¶</a></h2>
<p>One of the benefits of decoupling the client connection handling from work
processing is that it means you can run new code without dropping client
connections; this is especially useful for WebSockets.</p>
<p>Just restart your workers when you have new code (by default, if you send
them SIGTERM they&#8217;ll cleanly exit and finish running any in-process
consumers), and any queued messages or new connections will go to the new
workers. As long as the new code is session-compatible, you can even do staged
rollouts to make sure workers on new code aren&#8217;t experiencing high error rates.</p>
<p>There&#8217;s no need to restart the WSGI or WebSocket interface servers unless
you&#8217;ve upgraded the interface server itself or changed the <code class="docutils literal"><span class="pre">CHANNEL_LAYER</span></code>
setting; none of your code is used by them, and all middleware and code that can
customize requests is run on the consumers.</p>
<p>You can even use different Python versions for the interface servers and the
workers; the ASGI protocol that channel layers communicate over
is designed to be portable across all Python versions.</p>
</div>
<div class="section" id="running-just-asgi">
<span id="asgi-alone"></span><h2>Running just ASGI<a class="headerlink" href="#running-just-asgi" title="本標題的永久連結">¶</a></h2>
<p>If you are just running Daphne to serve all traffic, then the configuration
above is enough where you can just expose it to the Internet and it&#8217;ll serve
whatever kind of request comes in; for a small site, just the one Daphne
instance and four or five workers is likely enough.</p>
<p>However, larger sites will need to deploy things at a slightly larger scale,
and how you scale things up is different from WSGI; see <a class="reference internal" href="#scaling-up"><span class="std std-ref">Scaling Up</span></a>.</p>
</div>
<div class="section" id="running-asgi-alongside-wsgi">
<span id="wsgi-with-asgi"></span><h2>Running ASGI alongside WSGI<a class="headerlink" href="#running-asgi-alongside-wsgi" title="本標題的永久連結">¶</a></h2>
<p>ASGI and its canonical interface server Daphne are both relatively new,
and so you may not wish to run all your traffic through it yet (or you may
be using specialized features of your existing WSGI server).</p>
<p>If that&#8217;s the case, that&#8217;s fine; you can run Daphne and a WSGI server alongside
each other, and only have Daphne serve the requests you need it to (usually
WebSocket and long-poll HTTP requests, as these do not fit into the WSGI model).</p>
<p>To do this, just set up your Daphne to serve as we discussed above, and then
configure your load-balancer or front HTTP server process to dispatch requests
to the correct server - based on either path, domain, or if
you can, the Upgrade header.</p>
<p>Dispatching based on path or domain means you&#8217;ll need to design your WebSocket
URLs carefully so you can always tell how to route them at the load-balancer
level; the ideal thing is to be able to look for the <code class="docutils literal"><span class="pre">Upgrade:</span> <span class="pre">WebSocket</span></code>
header and distinguish connections by this, but not all software supports this
and it doesn&#8217;t help route long-poll HTTP connections at all.</p>
<p>You could also invert this model, and have all connections go to Daphne by
default and selectively route some back to the WSGI server, if you have
particular URLs or domains you want to use that server on.</p>
</div>
<div class="section" id="running-on-a-paas">
<h2>Running on a PaaS<a class="headerlink" href="#running-on-a-paas" title="本標題的永久連結">¶</a></h2>
<p>To run Django with channels enabled on a Platform-as-a-Service (PaaS), you will
need to ensure that your PaaS allows you to run multiple processes at different
scaling levels; one group will be running Daphne, as a pure Python application
(not a WSGI application), and the other should be running <code class="docutils literal"><span class="pre">runworker</span></code>.</p>
<p>The PaaS will also either have to provide either its own Redis service or
a third process type that lets you run Redis yourself to use the cross-network
channel backend; both interface and worker processes need to be able to see
Redis, but not each other.</p>
<p>If you are only allowed one running process type, it&#8217;s possible you could
combine both interface server and worker into one process using threading
and the in-memory backend; however, this is not recommended for production
use as you cannot scale up past a single node without groups failing to work.</p>
</div>
<div class="section" id="scaling-up">
<span id="id1"></span><h2>Scaling Up<a class="headerlink" href="#scaling-up" title="本標題的永久連結">¶</a></h2>
<p>Scaling up a deployment containing channels (and thus running ASGI) is a little
different to scaling a WSGI deployment.</p>
<p>The fundamental difference is that the group mechanic requires all servers serving
the same site to be able to see each other; if you separate the site up and run
it in a few, large clusters, messages to groups will only deliver to WebSockets
connected to the same cluster. For some site designs this will be fine, and if
you think you can live with this and design around it (which means never
designing anything around global notifications or events), this may be a good
way to go.</p>
<p>For most projects, you&#8217;ll need to run a single channel layer at scale in order
to achieve proper group delivery. Different backends will scale up differently,
but the Redis backend can use multiple Redis servers and spread the load
across them using sharding based on consistent hashing.</p>
<p>The key to a channel layer knowing how to scale a channel&#8217;s delivery is if it
contains the <code class="docutils literal"><span class="pre">!</span></code> character or not, which signifies a single-reader channel.
Single-reader channels are only ever connected to by a single process, and so
in the Redis case are stored on a single, predictable shard. Other channels
are assumed to have many workers trying to read them, and so messages for
these can be evenly divided across all shards.</p>
<p>Django channels are still relatively new, and so it&#8217;s likely that we don&#8217;t yet
know the full story about how to scale things up; we run large load tests to
try and refine and improve large-project scaling, but it&#8217;s no substitute for
actual traffic. If you&#8217;re running channels at scale, you&#8217;re encouraged to
send feedback to the Django team and work with us to hone the design and
performance of the channel layer backends, or you&#8217;re free to make your own;
the ASGI specification is comprehensive and comes with a conformance test
suite, which should aid in any modification of existing backends or development
of new ones.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">目錄</a></h3>
  <ul>
<li><a class="reference internal" href="#">配置</a><ul>
<li><a class="reference internal" href="#setting-up-a-channel-backend">Setting up a channel backend</a></li>
<li><a class="reference internal" href="#run-worker-servers">執行使用者伺服器</a></li>
<li><a class="reference internal" href="#run-interface-servers">Run interface servers</a></li>
<li><a class="reference internal" href="#deploying-new-versions-of-code">Deploying new versions of code</a></li>
<li><a class="reference internal" href="#running-just-asgi">Running just ASGI</a></li>
<li><a class="reference internal" href="#running-asgi-alongside-wsgi">Running ASGI alongside WSGI</a></li>
<li><a class="reference internal" href="#running-on-a-paas">Running on a PaaS</a></li>
<li><a class="reference internal" href="#scaling-up">Scaling Up</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="getting-started.html" title="上一章">Getting Started with Channels</a></li>
      <li>Next: <a href="generics.html" title="下一章">一般消費者</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>本頁</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/deploying.rst.txt"
            rel="nofollow">顯示原始碼</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜尋</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="前往" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, chairco(Jason).
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/deploying.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>